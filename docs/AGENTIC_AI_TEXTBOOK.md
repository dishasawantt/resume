# Agentic AI: A Comprehensive Guide
## From Concepts to Implementation - A Beginner's Textbook

---

## Table of Contents

1. [Introduction: The Evolution of AI Assistants](#1-introduction)
2. [What is Agentic AI?](#2-what-is-agentic-ai)
3. [Core Components of Agentic AI Systems](#3-core-components)
4. [Large Language Models: The Brain](#4-large-language-models)
5. [Tool Calling: Giving AI Hands](#5-tool-calling)
6. [Memory & Context: The AI's Notebook](#6-memory-and-context)
7. [Planning & Reasoning](#7-planning-and-reasoning)
8. [Our Implementation: The Portfolio Chatbot](#8-our-implementation)
9. [Best Practices & Lessons Learned](#9-best-practices)
10. [The Future of Agentic AI](#10-future)

---

## 1. Introduction: The Evolution of AI Assistants

### From Simple Chatbots to Intelligent Agents

Remember those old chatbots that could only answer "What are your hours?" or "How do I reset my password?" They worked by matching keywords to pre-written responses. Ask them anything unexpected, and they'd say "I don't understand. Please rephrase."

Then came **Large Language Models (LLMs)** like GPT, Claude, and LLaMA. These could understand natural language, hold conversations, and even write poetry. But they had a limitation: they could only *talk*. They couldn't *do* anything.

Ask ChatGPT to "send an email to John" and it would write a beautiful email... but you'd still have to copy-paste it into Gmail yourself.

**Agentic AI** bridges this gap. It's AI that doesn't just think and talkâ€”it **takes action**.

### The Three Generations of Conversational AI

| Generation | Example | Capabilities | Limitations |
|------------|---------|--------------|-------------|
| **Rule-Based** | Old customer service bots | Pattern matching, fixed responses | No understanding, brittle |
| **LLM-Powered** | ChatGPT, Claude | Natural conversation, reasoning | Can only generate text |
| **Agentic AI** | This chatbot! | Conversation + real-world actions | Needs careful design |

---

## 2. What is Agentic AI?

### Definition

**Agentic AI** refers to AI systems that can:
1. **Understand** what the user wants
2. **Plan** how to achieve it
3. **Take action** using tools and APIs
4. **Verify** the results
5. **Adapt** if something goes wrong

Think of it like the difference between asking someone for directions (they tell you) versus hiring a taxi (they take you there). Agentic AI is the taxi.

### The "Agency" Spectrum

Not all AI systems are equally "agentic." There's a spectrum:

```
Less Agentic â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º More Agentic

Simple Chatbot â†’ Tool-Using AI â†’ Autonomous Agent â†’ Multi-Agent System
     â”‚                â”‚                  â”‚                  â”‚
  Just talks    Can call APIs    Plans & executes    Multiple AIs
                                 multi-step tasks    collaborate
```

**Our chatbot sits in the "Tool-Using AI" zone**â€”it can understand requests, decide when to use tools, and execute them with user approval.

### Real-World Examples of Agentic AI

| System | What It Does | Level of Agency |
|--------|-------------|-----------------|
| **Siri/Alexa** | Voice commands, limited actions | Low-Medium |
| **GitHub Copilot** | Writes code, suggests fixes | Medium |
| **Cursor AI** | Edits files, runs commands | Medium-High |
| **Auto-GPT** | Sets goals, plans, executes | High |
| **Our Chatbot** | Schedules meetings, sends emails | Medium |

---

## 3. Core Components of Agentic AI Systems

Every agentic AI system has these building blocks:

### 3.1 The "Brain" - Large Language Model

The LLM understands language, reasons about problems, and decides what to do. It's the intelligence behind everything.

### 3.2 The "Hands" - Tools/Functions

Tools are how the AI interacts with the real world. APIs, databases, email servicesâ€”anything the AI can call.

### 3.3 The "Memory" - Context Management

The AI needs to remember what was said earlier in the conversation and sometimes across sessions.

### 3.4 The "Judgment" - Planning & Reasoning

The AI must decide *when* to use tools, *which* tools to use, and *how* to handle errors.

### 3.5 The "Safety Net" - Human Oversight

Most agentic systems include checkpoints where humans can approve or reject actions.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AGENTIC AI SYSTEM                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  USER   â”‚â”€â”€â”€â–ºâ”‚   LLM   â”‚â”€â”€â”€â–ºâ”‚  TOOLS  â”‚â”€â”€â”€â–ºâ”‚ RESULT  â”‚  â”‚
â”‚  â”‚  INPUT  â”‚    â”‚ (Brain) â”‚    â”‚ (Hands) â”‚    â”‚         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                      â”‚                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â”‚    MEMORY     â”‚                              â”‚
â”‚              â”‚  (Notebook)   â”‚                              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Large Language Models: The Brain

### What is an LLM?

A Large Language Model is a neural network trained on massive amounts of text. It learns patterns in languageâ€”grammar, facts, reasoning, even personalityâ€”and can generate human-like responses.

When you type "Tell me about yourself," the LLM doesn't search a database. It *generates* a response word by word, predicting what comes next based on patterns it learned during training.

### LLM Providers: Your Options

There are many LLM providers. Here's a comprehensive comparison:

#### Commercial/Closed-Source Providers

| Provider | Models | Strengths | Weaknesses | Pricing |
|----------|--------|-----------|------------|---------|
| **OpenAI** | GPT-4o, GPT-4-turbo, GPT-3.5 | Best overall quality, huge ecosystem | Expensive, data privacy concerns | $0.01-$0.06 per 1K tokens |
| **Anthropic** | Claude 3.5 Sonnet, Claude 3 Opus | Excellent reasoning, safety-focused | Smaller ecosystem | $0.003-$0.015 per 1K tokens |
| **Google** | Gemini Pro, Gemini Ultra | Multimodal, Google integration | Variable quality | Free tier available |
| **Cohere** | Command R+, Embed | Good for enterprise, RAG-focused | Less general-purpose | $0.001 per 1K tokens |

#### Open-Source Friendly Providers

| Provider | Models | Strengths | Weaknesses | Pricing |
|----------|--------|-----------|------------|---------|
| **Groq** â­ | LLaMA 3.3, Mixtral, Gemma | Blazing fast, free tier | Limited model selection | Free tier: 30 req/min |
| **Together AI** | Many open models | Flexible, good pricing | Less polished | $0.0002-$0.002 per 1K tokens |
| **Fireworks AI** | LLaMA, Mixtral, custom | Fast, function calling | Smaller ecosystem | $0.0002 per 1K tokens |
| **Replicate** | Any open model | Run anything | Pay per compute time | Variable |

#### Self-Hosted Options

| Option | Pros | Cons |
|--------|------|------|
| **Ollama** | Free, private, runs locally | Need good hardware |
| **vLLM** | Production-ready, fast | Complex setup |
| **Text Generation WebUI** | User-friendly | Resource intensive |

### Why We Chose Groq

For this portfolio chatbot, we use **Groq** with the **LLaMA 3.3 70B** model. Here's why:

1. **Speed**: Groq's custom LPU chips process tokens incredibly fast
2. **Free Tier**: 30 requests/minute, 14,400/dayâ€”enough for a portfolio
3. **Tool Calling Support**: Native function calling capability
4. **Open Model**: LLaMA is open-source, well-documented
5. **Simple API**: Compatible with OpenAI's API format

```javascript
// Our implementation uses Groq SDK
const Groq = require("groq-sdk");
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

const completion = await groq.chat.completions.create({
    messages: [...],
    model: "llama-3.3-70b-versatile",
    tools: TOOLS,
    tool_choice: "auto"
});
```

### The API Pattern

Almost all LLM providers use a similar API pattern:

```javascript
// Generic pattern (works with OpenAI, Groq, Anthropic, etc.)
const response = await client.chat.completions.create({
    model: "model-name",
    messages: [
        { role: "system", content: "You are a helpful assistant" },
        { role: "user", content: "Hello!" },
        { role: "assistant", content: "Hi there!" },
        { role: "user", content: "What can you do?" }
    ],
    temperature: 0.7,
    max_tokens: 250,
    tools: [...],
    tool_choice: "auto"
});
```

---

## 5. Tool Calling: Giving AI Hands

### What is Tool Calling?

Tool calling (also called "function calling") is how we give an LLM the ability to take actions. Instead of just generating text, the LLM can say "I need to call a function" and specify what to call.

Think of it like this:

**Without tools:**
> User: "Send my resume to john@company.com"
> AI: "I've drafted an email for you: 'Dear John, Please find my resume attached...'"
> *(You still have to send it yourself)*

**With tools:**
> User: "Send my resume to john@company.com"
> AI: *[Calls send_resume function with email="john@company.com"]*
> AI: "Done! I've sent your resume to john@company.com"

### How Tool Calling Works

The process has four steps:

```
1. DEFINE      2. DESCRIBE       3. DECIDE         4. EXECUTE
   Tools  â”€â”€â”€â–º   To LLM    â”€â”€â”€â–º   LLM Chooses â”€â”€â”€â–º   Run Function
                                  (or not)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚send_emailâ”‚   â”‚"send_email: â”‚   â”‚ LLM says:  â”‚   â”‚ Actually    â”‚
â”‚schedule_ â”‚â”€â”€â–ºâ”‚ sends email â”‚â”€â”€â–ºâ”‚ Call send_ â”‚â”€â”€â–ºâ”‚ send the    â”‚
â”‚meeting   â”‚   â”‚ to someone" â”‚   â”‚ email with â”‚   â”‚ email!      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ these args â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Defining Tools

Tools are defined using JSON Schema. You describe:
- The function name
- What it does (so the LLM knows when to use it)
- Required parameters

Here's how we defined our tools:

```javascript
const TOOLS = [
    {
        type: "function",
        function: {
            name: "send_documents",
            description: "Send resume to visitor. ONLY when user explicitly says 'mail/send/email me resume'. MUST have real name AND email first.",
            parameters: {
                type: "object",
                properties: {
                    recipientName: { 
                        type: "string", 
                        description: "Recipient's actual name" 
                    },
                    recipientEmail: { 
                        type: "string", 
                        description: "Recipient's actual email" 
                    },
                    documents: { 
                        type: "array", 
                        items: { type: "string", enum: ["resume"] } 
                    }
                },
                required: ["recipientName", "recipientEmail", "documents"]
            }
        }
    },
    {
        type: "function",
        function: {
            name: "schedule_meeting",
            description: "Generate scheduling link. ONLY when user explicitly asks to schedule/book a meeting/call.",
            parameters: {
                type: "object",
                properties: {
                    meetingType: { 
                        type: "string", 
                        enum: ["quick_chat", "consultation", "interview"] 
                    }
                },
                required: ["meetingType"]
            }
        }
    }
];
```

### The LLM's Response with Tool Calls

When the LLM decides to use a tool, its response looks different:

**Normal response (no tool):**
```json
{
    "choices": [{
        "message": {
            "role": "assistant",
            "content": "I'm a software engineer with experience in..."
        }
    }]
}
```

**Tool call response:**
```json
{
    "choices": [{
        "message": {
            "role": "assistant",
            "content": null,
            "tool_calls": [{
                "id": "call_abc123",
                "type": "function",
                "function": {
                    "name": "send_documents",
                    "arguments": "{\"recipientName\":\"John\",\"recipientEmail\":\"john@test.com\",\"documents\":[\"resume\"]}"
                }
            }]
        }
    }]
}
```

### Alternative Approaches to Tool Calling

Tool calling isn't the only way to give AI agency. Here are alternatives:

| Approach | How It Works | Pros | Cons |
|----------|--------------|------|------|
| **Native Tool Calling** (what we use) | LLM has built-in function calling | Clean, reliable | Not all models support it |
| **Prompt Engineering** | Ask LLM to output JSON actions | Works with any model | More parsing errors |
| **ReAct Pattern** | LLM outputs Thought â†’ Action â†’ Observation | Better reasoning | Verbose, slow |
| **Code Generation** | LLM writes executable code | Very flexible | Security risks |

### Our Tool Implementation

Here's how our chatbot handles tool calls:

```javascript
// Check if LLM wants to use a tool
if (resp.tool_calls?.length) {
    const { name: fn, arguments: argsStr } = resp.tool_calls[0].function;
    const args = JSON.parse(argsStr);
    
    // Validate parameters
    const validation = validateToolParams(fn, args);
    if (!validation.valid) {
        return { response: validation.message };
    }
    
    // Return with approval request
    return {
        response: `I'll send my resume to ${args.recipientEmail}. Proceed?`,
        toolCall: { function: fn, arguments: args, requiresApproval: true }
    };
}
```

---

## 6. Memory & Context: The AI's Notebook

### The Memory Challenge

LLMs don't have persistent memory. Each API call is statelessâ€”the model doesn't remember previous conversations unless you tell it.

When you chat with ChatGPT, it's actually receiving the *entire conversation* with every message. The "memory" is just copy-pasting earlier messages.

### Types of Memory in AI Systems

| Type | Duration | Use Case | Storage |
|------|----------|----------|---------|
| **Conversation History** | One session | Remember what was said | In-memory array |
| **Short-Term Context** | Few messages | Keep recent context | Sliding window |
| **Long-Term Memory** | Persistent | Remember across sessions | Database |
| **Semantic Memory** | Persistent | Knowledge retrieval | Vector DB |

### How Context Windows Work

Every LLM has a **context window**â€”the maximum amount of text it can process at once.

| Model | Context Window | Approximate Words |
|-------|---------------|-------------------|
| GPT-3.5 | 4,096 tokens | ~3,000 words |
| GPT-4 | 128,000 tokens | ~96,000 words |
| Claude 3.5 | 200,000 tokens | ~150,000 words |
| LLaMA 3.3 70B | 128,000 tokens | ~96,000 words |

**Token â‰ˆ 0.75 words** (roughly)

If your conversation exceeds the context window, you have to truncate it.

### Our Memory Strategy

We use a **sliding window** approach:

```javascript
// Only keep last 4 messages in history
const cleanHistory = history.slice(-4).filter(msg => {
    if (msg.role !== 'assistant') return true;
    const c = msg.content?.toLowerCase() || '';
    // Keep info-gathering messages
    if (/what's your|what is your/i.test(c)) return true;
    // Filter out tool confirmations
    return !/(scheduling link|i'll send|i've sent)/i.test(c);
});

// Send to LLM
const completion = await groq.chat.completions.create({
    messages: [
        { role: "system", content: SYSTEM_PROMPT },
        ...cleanHistory,
        { role: "user", content: message }
    ],
});
```

### The System Prompt

The **system prompt** is special context that shapes the AI's behavior. It's always included and acts like the AI's "personality instructions."

```javascript
const SYSTEM_PROMPT = `You ARE Disha Sawant on your portfolio chatbot. 
Warm, concise (2-3 sentences), no emojis.

CONTACT: dishasawantt@gmail.com | 619-918-7729
BACKGROUND: MS CompE SDSU (2024-26) | BS Mumbai (2018-22)
SKILLS: Python, JS, TensorFlow, PyTorch, React, FastAPI

TOOL RULES:
- send_documents: ONLY with real name + valid email. Ask if missing.
- schedule_meeting: ONLY when user explicitly asks to schedule/book.

RULES: First person only. Never show JSON. Never invent info.`;
```

### Advanced Memory Techniques (Not Used Here)

For more sophisticated applications, you might use:

| Technique | What It Does | When to Use |
|-----------|--------------|-------------|
| **RAG (Retrieval-Augmented Generation)** | Search a knowledge base and inject relevant info | Large documentation |
| **Vector Databases** | Store and search by meaning, not keywords | Semantic search |
| **Summarization** | Compress long conversations | Long chats |
| **Entity Extraction** | Remember key facts about users | Personalization |

We actually use a simple form of RAG for LinkedIn connections:

```javascript
// Search LinkedIn connections and inject results
const matches = searchConnections(nameQuery);
connectionContext = matches.length 
    ? `\n\n[LINKEDIN] Found: ${matches.map(formatConnection).join('; ')}`
    : `\n\n[LINKEDIN] No connection named "${nameQuery}" found.`;

// Inject into system prompt
{ role: "system", content: SYSTEM_PROMPT + connectionContext }
```

---

## 7. Planning & Reasoning

### How AI "Decides" What to Do

When the LLM receives a message, it must decide:
1. Should I just respond with text?
2. Should I use a tool? Which one?
3. Do I have enough information?
4. Should I ask for clarification?

This decision-making happens through **prompting**â€”instructions in the system prompt that guide behavior.

### Prompt Engineering for Agents

Good prompts for agentic AI include:

**1. Clear Role Definition**
```
You ARE Disha Sawant responding on your portfolio chatbot.
```

**2. Behavioral Guidelines**
```
Warm, concise (2-3 sentences), no emojis.
First person only ("I", "my", "me")
```

**3. Tool Usage Rules**
```
ONLY use send_documents when ALL conditions are met:
1. User explicitly says "send me", "mail me", "email me" + resume
2. You have the user's REAL name
3. You have a VALID email address
If ANY condition is missing â†’ ASK for it.
```

**4. Negative Examples**
```
NEVER USE TOOLS FOR:
- Questions about people/connections
- "How can I contact you?"
- General questions
```

### Common Agentic Patterns

#### Pattern 1: ReAct (Reasoning + Acting)

```
Thought: User wants to send resume. I need their name and email.
Action: Ask for name
Observation: User said "John"
Thought: Now I need email.
Action: Ask for email
Observation: User said "john@test.com"
Thought: I have both. Ready to send.
Action: call send_documents(name="John", email="john@test.com")
```

#### Pattern 2: Chain of Thought

```
Let me think step by step:
1. User asked about Usha Sawant
2. This is a question about a person
3. I should search LinkedIn connections
4. Found: Usha Sawant at Wipro
5. I'll share this information
```

#### Pattern 3: Tool Selection

```
Available tools: send_documents, schedule_meeting
User message: "Can we have a call?"
Analysis: "call" suggests a meeting â†’ use schedule_meeting
```

### Validation: The Human Safety Net

For actions that affect the real world, we add validation:

```javascript
function validateToolParams(fn, args) {
    if (fn !== 'send_documents') return { valid: true };
    const { recipientName: name, recipientEmail: email } = args;
    
    // Check for missing name
    if (!name || name.length < 2 || /your name|user's/i.test(name))
        return { valid: false, message: "What's your name?" };
    
    // Check for valid email
    if (!email?.includes('@') || !isValidEmail(email))
        return { valid: false, message: `Thanks ${name}! What's your email?` };
    
    return { valid: true };
}
```

And user approval:

```javascript
return {
    response: `I'll send my resume to ${email}. Proceed?`,
    toolCall: { function: fn, arguments: args, requiresApproval: true }
};
```

---

## 8. Our Implementation: The Portfolio Chatbot

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FRONTEND                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ avatar.html â”‚  â”‚  avatar.js   â”‚  â”‚     avatar.css        â”‚   â”‚
â”‚  â”‚   (UI)      â”‚  â”‚  (Logic)     â”‚  â”‚     (Styling)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      /api/chat                              â”‚ â”‚
â”‚  â”‚              (Netlify Functions)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BACKEND                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    chat.js                               â”‚   â”‚
â”‚  â”‚  â€¢ Receives message + history                            â”‚   â”‚
â”‚  â”‚  â€¢ Searches LinkedIn connections (if name query)         â”‚   â”‚
â”‚  â”‚  â€¢ Calls Groq API (LLaMA 3.3)                           â”‚   â”‚
â”‚  â”‚  â€¢ Handles tool calls                                    â”‚   â”‚
â”‚  â”‚  â€¢ Returns response                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚           â–¼                â–¼                â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ send-doc.js â”‚  â”‚schedule.js  â”‚  â”‚  connections.json   â”‚     â”‚
â”‚  â”‚ (SendGrid)  â”‚  â”‚ (Calendly)  â”‚  â”‚  (LinkedIn data)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXTERNAL SERVICES                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚   Groq   â”‚  â”‚   SendGrid   â”‚  â”‚  Calendly  â”‚                â”‚
â”‚  â”‚  (LLM)   â”‚  â”‚   (Email)    â”‚  â”‚ (Schedule) â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Files Explained

| File | Purpose | Lines |
|------|---------|-------|
| `avatar.js` | Frontend logic, UI interactions, voice, typing effect | ~575 |
| `chat.js` | Main API, LLM calls, tool routing, validation | ~230 |
| `send-document.js` | Email sending via SendGrid | ~88 |
| `schedule-meeting.js` | Calendly link generation | ~54 |
| `utils.js` | Shared utilities, rate limiting | ~35 |
| `connections.json` | LinkedIn network data | ~14,000 |

### The Complete Flow

Let's trace what happens when you say "Can you email me your resume?":

```
USER: "Can you email me your resume?"
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Frontend (avatar.js)             â”‚
â”‚    â€¢ Add to conversation history    â”‚
â”‚    â€¢ POST to /api/chat              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Backend (chat.js)                â”‚
â”‚    â€¢ Parse request                  â”‚
â”‚    â€¢ Not a name query â†’ skip search â”‚
â”‚    â€¢ Build messages array           â”‚
â”‚    â€¢ Call Groq API                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Groq (LLaMA 3.3)                 â”‚
â”‚    â€¢ Understands: user wants resume â”‚
â”‚    â€¢ Decides: need name + email     â”‚
â”‚    â€¢ Returns: ask for name          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Response                         â”‚
â”‚    { response: "What's your name?" }â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
USER: "John Smith"
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. LLM sees history, knows context  â”‚
â”‚    Returns: ask for email           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
USER: "john@test.com"
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. LLM has name + email             â”‚
â”‚    Returns: tool_call for           â”‚
â”‚    send_documents                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Validation passes                â”‚
â”‚    Return with requiresApproval     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. Frontend shows approve button    â”‚
â”‚    User clicks "Send Documents"     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. Tool execution                   â”‚
â”‚    send-document.js calls SendGrid  â”‚
â”‚    Email sent!                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
AI: "Done! I've sent my resume to john@test.com"
```

### LinkedIn Connection Search (Simple RAG)

One clever feature is searching LinkedIn connections:

```javascript
// Extract name from queries like "Do you know John Smith?"
function extractNameQuery(msg) {
    if (/mail|send|email|resume|schedule/i.test(msg)) return null;
    
    const patterns = [
        /do you know (\w+(?:\s+\w+){0,2})/i,
        /who(?:'?s| is) (\w+(?:\s+\w+){0,2})/i,
        /tell me about (\w+(?:\s+\w+){0,2})/i,
    ];
    
    for (const p of patterns) {
        const m = msg.match(p);
        if (m?.[1]?.length > 2) return m[1].trim();
    }
    return null;
}

// Search with scoring
function searchConnections(query) {
    const terms = query.toLowerCase().split(/\s+/);
    
    return connections
        .map(c => {
            const name = c.name.toLowerCase();
            let score = 0;
            
            if (name === terms.join(' ')) score = 100;
            else if (terms.every(t => name.includes(t))) score = 50;
            else if (terms.some(t => name.includes(t))) score = 5;
            
            return score > 0 ? { c, score } : null;
        })
        .filter(Boolean)
        .sort((a, b) => b.score - a.score)
        .slice(0, 3)
        .map(r => r.c);
}

// Inject into context
connectionContext = `\n\n[LINKEDIN] Found: ${matches.map(formatConnection).join('; ')}`;
```

---

## 9. Best Practices & Lessons Learned

### 1. Be Explicit in Tool Descriptions

**Bad:**
```javascript
description: "Send email"
```

**Good:**
```javascript
description: "Send resume to visitor. ONLY when user explicitly says 'mail/send/email me resume'. MUST have real name AND email first."
```

The LLM reads these descriptions to decide when to use tools. Vague descriptions lead to wrong tool calls.

### 2. Validate Everything

LLMs can hallucinate parameters. Always validate:

```javascript
// LLM might return "user's name" as the name
if (/your name|user's|placeholder/i.test(name)) {
    return { valid: false, message: "What's your name?" };
}
```

### 3. Use Approval Gates for Actions

Don't let AI send emails or book meetings without user confirmation:

```javascript
return {
    response: "I'll send my resume. Should I proceed?",
    toolCall: { ...args, requiresApproval: true }
};
```

### 4. Keep Context Small

More context = more tokens = more cost + slower responses:

```javascript
// Only last 4 messages, not entire history
const cleanHistory = history.slice(-4);
```

### 5. Handle Errors Gracefully

```javascript
try {
    const res = await groq.chat.completions.create({...});
} catch (error) {
    if (error.status === 429) {
        return "Rate limit reached. Please wait a moment.";
    }
    return "Something went wrong. Please try again.";
}
```

### 6. Rate Limit on Client Side Too

Don't rely only on API rate limits:

```javascript
let lastRequestTime = 0;
const REQUEST_COOLDOWN = 2000; // 2 seconds

async function handleSend() {
    const now = Date.now();
    if (now - lastRequestTime < REQUEST_COOLDOWN) return;
    lastRequestTime = now;
}
```

### 7. Log Everything (During Development)

```javascript
log('ðŸ” Connection search:', nameQuery, 'â†’', matches.length);
log('ðŸ”§ Tool Call:', fn, args);
log('âŒ Validation failed:', validation.message);
```

### 8. Test Edge Cases

- What if user gives email before name?
- What if they type just "send"?
- What if the LLM hallucinates a tool call?
- What if the external API is down?

---

## 10. The Future of Agentic AI

### What's Coming

| Trend | Description | Timeline |
|-------|-------------|----------|
| **Multi-Agent Systems** | Multiple AIs collaborating | Now |
| **Longer Context** | 1M+ token windows | 2024-2025 |
| **Better Reasoning** | Chain-of-thought built in | 2024-2025 |
| **Computer Use** | AI controlling mouse/keyboard | 2024-2025 |
| **Autonomous Agents** | Goal-setting, self-correcting | 2025+ |

### Emerging Patterns

**1. Multi-Agent Orchestration**
Instead of one AI doing everything, specialized agents collaborate:
- Planner Agent â†’ Research Agent â†’ Writer Agent â†’ Reviewer Agent

**2. Computer Use**
Anthropic's Claude can now see screens and click buttonsâ€”AI that uses computers like humans do.

**3. Memory Systems**
Persistent memory across sessions with vector databases and knowledge graphs.

**4. Self-Improvement**
Agents that learn from their mistakes and improve over time.

### Your Next Steps

1. **Experiment**: Try different LLM providers
2. **Add Tools**: What else could your chatbot do?
3. **Add Memory**: Implement persistent user preferences
4. **Add RAG**: Connect to a knowledge base
5. **Try Multi-Agent**: Split responsibilities between specialized bots

---

## Glossary

| Term | Definition |
|------|------------|
| **LLM** | Large Language Model - AI trained on text to generate human-like responses |
| **Token** | The unit LLMs use; roughly 0.75 words |
| **Context Window** | Maximum text an LLM can process at once |
| **System Prompt** | Instructions that shape AI behavior |
| **Tool Calling** | LLM's ability to invoke external functions |
| **RAG** | Retrieval-Augmented Generation - searching and injecting knowledge |
| **Agentic** | AI that can take actions, not just generate text |
| **Hallucination** | When AI generates false information |
| **Fine-tuning** | Training a model on custom data |
| **Embedding** | Converting text to numbers for similarity search |

---

## References & Further Reading

1. **LangChain Documentation** - Framework for building LLM applications
2. **OpenAI Function Calling Guide** - Official tool calling documentation
3. **Anthropic Claude Prompt Engineering** - Best practices for prompts
4. **Groq Documentation** - API reference for our LLM provider
5. **ReAct Paper** - The reasoning + acting pattern

---

*This document explains the concepts and implementation of the portfolio chatbot at dishasawantt.github.io/resume. The chatbot demonstrates practical agentic AI with tool calling, context management, and real-world integrations.*

